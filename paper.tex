\documentclass{article}
\usepackage{url,color,xspace,verbatim,subfig,ctable,multirow,listings}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{txfonts}
\usepackage{rotating}
\usepackage{paralist}
\usepackage{subfig}
\usepackage{graphics}
\usepackage{enumitem}
\usepackage{times}
\usepackage{amssymb}
\usepackage[colorlinks=true]{hyperref}

% ==================================================

\graphicspath{{figs/}}
\urlstyle{sf}

% tikz stuff
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{shapes,positioning,calc,snakes,arrows,shapes}

\lstset{
  language=C,
  basicstyle=\ttfamily \small,
  flexiblecolumns=false,
  basewidth={0.5em,0.45em},
  boxpos=t,
}

\definecolor{skRed}{RGB}{155,25,25}
\newcommand{\stefan}[1]{
  {\color{skRed}[{\color{red}{SK}} #1]}}

% ==================================================

\begin{document}

\title{Replication on multicore considering hierarchy and
  characteristics of the network}

% email address
\newcommand{\eaddr}{stefan.kaestle@inf.ethz.ch}
\newcommand{\email}{\href{mailto:\eaddr}{\eaddr}}

\author{Stefan Kaestle\\
  \email \\
  Systems Group, ETH Zurich}

\maketitle

\paragraph{What do you want to enable?} Increase algorithm performance
on multicores by applying distributed principles, particularly
replication. The challenge then is to guarantee consistency. Previous
work was using primary copy protocols to do that~\cite{Wiesmann2000}, a
passive replication scheme (i.e.\ nodes do not have to contact all
replicas). They do that because they claim that it is not suitable for
clients to know about replication details. An atomic broadcast is
often used as foundation of such algorithms. It guarantees in reliable
delivery of messages to every node.

\paragraph{What problem are you solving, and why is it hard?} Three problems:
\begin{description}
\item[placement] machine dependent
\item[consistency] need to consider machine \emph{characteristics};
  multicores are \emph{different} from classical distributed systems.
\item[machine characteristics] diverse, fast changing, complex. One
  example is the batch size for sending a broadcast.
\end{description}

\paragraph{What's the related work?} People do replication to deal
with scalability challenges on multicores, e.g.\
databases~\cite{Salomie2011, Wiesmann2000} and operating
systems~\cite{fos:osr09, tornado:osdi99, barrelfish:sosp09}. But they
don't to it properly. They do not consider machine characteristics or
apply the wrong distributed technologies.

\paragraph{What new idea(s) will solve the problems?} We do a
hierarchical group communication, which implements an atomic
broadcast on multicore machines. It has message complexity of
$O(\frac{n}{2})$ and time complexity $O(log(n))$ as opposed to
algorithms from traditional distributed systems having $O(2)$ message
complexity and $O(n)$ time complexity. %
\\
{\footnotesize Example: sequential consistency on shared memory, do
  not really need to have primary backup.}

\paragraph{How will you go about it?} Replicas on NUMA domains, show
that overall throughput is higher. Then, use a quorum based approach for
consistency. Consistency by doing a hierarchical group communication
approach instead of sequential send from same nodes.

\paragraph{How will you know and show it works?} Database?
Microbenchmark? Compare to primary backup, which is typically
used. Measure time required to apply an update.

\paragraph{What is your hypothesis?} We can do much better if machine
characteristics are considered.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mechanisms}

\subsubsection{Aggregation}

Similarly to what has been done in wireless sensor networks (where it
also matters to reduce the number of messages, but other reasons:
power consumption), we can do aggregation in nodes. In difference to
traditional distributed systems, this works, because it is easy to
deploy custom software on every node in the network. Classical
distributed systems do not typically allow this. Furthermore, reducing
the number of messages at the price of higher complexity does not make
sense there.

Examples for aggregation: number of nodes agreeing to something, find
capabilities (concatenate core ids). 

Open questions: How does this work with several senders (everyone is
potentially a sender). Maybe something like in navigation
systems. Every node has an entry point, which forwards the
messages. Nodes are then clustered \ldots

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Implementation}

Build a tree. Every node has parents and children (except for the root
and the leafs). The number of children does not really matter for the
algorithm. In the init phase, we construct the tree (e.g. broadcast:
one root node, all other nodes are children of the root node,
multicast: every node has two children, NUMA tree: two layers, two
different implementations?

Reducing the number of children also helps in select. It reduces the
number of ``channels'' to poll, and therefore the latency of detecting
messages. Instead of 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Experimental results}

\paragraph{Current numbers}

\begin{table}[htb]
  \centering
  \begin{tabular}{lrrrr}
    \toprule
    broadcast algorithm & \multicolumn{2}{c}{nos5} & \multicolumn{2}{c}{gruyere} \\
      & cycles & error & cycles & error \\
    \midrule
    sequential &  4096.1 &  105.2 & 136751.9 &   3061.5 \\
    batch      &  2408.0 &  181.9 &  57360.8 &   5271.5 \\
    \bottomrule
  \end{tabular}
  \caption{Broadcast measurements}
  \label{tab:bc_measurements}
\end{table}

\paragraph{Tree setup} \stefan{describe}

\paragraph{Measurements to do next} %
\begin{itemize}
\item Increase number of cores to talk to in every round. Use a
  separate waitsets, so that we don't have additional overhead from
  the bindings not used in each concrete measurement.
\item Play with batching. Incrementally increase the number of
  messages send in a batch. I assume this is machine specific, which
  means, that this is something programmers do not want to deal
  with. We measure this at dynamically at run-time and find the right
  batch size.
\end{itemize}

\paragraph{Minimal cost of sending a tree-broadcast} %
Plot~\ref{pgfplot:201303141819} shows the minimal cost of flooding a
sub-tree. The group communication is based on a binary tree. Core 0 is
the root, cores 1 and 2 are its children etc.

The average cost is really high (so something is wrong with my
code). But the minimal numbers show what is possible. The numbers
achieved are easily explainable. The cost is increasing
logarithmic with the number of nodes reached by the broadcast (as
expected). Every level in the tree adds an additional 3500 cycles to
the tree. Node 0 takes significantly longer. I don't know yet why that
is.

\begin{figure}
  \caption{Plot}
  \label{pgfplot:201303141819}
  \begin{tikzpicture}
    \begin{axis}[
      xlabel=core id,
      ylabel={cost for subtree [cycles]}]
    \addplot[color=red,mark=x] coordinates {
      (0,9475.0)
      (1,7935.0)
      (2,7894.0)
      (3,5965.0)
      (4,5604.0)
      (5,5718.0)
      (6,5647.0)
      (7,4316.0)
      (8,2989.0)
      (9,3173.0)
      (10,3395.0)
      (11,3332.0)
      (12,3284.0)
      (13,3310.0)
      (14,3231.0)
      (15,2542.0)
      (16,586.0)
      (17,588.0)
      (18,576.0)
      (19,583.0)
      (20,536.0)
      (21,539.0)
      (22,533.0)
      (23,516.0)
      (24,546.0)
      (25,552.0)
      (26,541.0)
      (27,543.0)
      (28,537.0)
      (29,527.0)
      (30,533.0)
      (31,534.0)
    };
    \end{axis}
  \end{tikzpicture}

\end{figure}
  
\begin{figure}
  \input{qrm_tree_gruyere}
  \caption{Tree of cores for broadcast on gruyere}
\end{figure}

\input{gruyere_bc_seq}

\begin{itemize}
\item Move server to a core != 0
\item Use low-level UMP stuff
{
\renewcommand{\labelitemi}{\checkmark}
\item disable yielding set 
}
\item some other item
\item run several request in parallel, give them IDs, can use in the
  measurement struct. Good for everything having transactions (DB,
  transactional memory, consistency in replication systems)
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\bibliographystyle{plain}
\bibliography{defs,db,mendeley}

\label{LastPage}

\end{document}
