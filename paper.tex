\documentclass{article}
\usepackage{url,color,xspace,verbatim,subfig,ctable,multirow,listings}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{txfonts}
\usepackage{rotating}
\usepackage{paralist}
\usepackage{subfig}
\usepackage{graphics}
\usepackage{enumitem}
\usepackage{times}
\usepackage{amssymb}
\usepackage[colorlinks=true]{hyperref}
\usepackage[ruled,vlined]{algorithm2e}

% ==================================================

\graphicspath{{figs/}}
\urlstyle{sf}

% tikz stuff
\usepackage{tikz}
\usepackage{pgfplots}
% configuration
\usetikzlibrary{shapes,positioning,calc,snakes,arrows,shapes}
\pgfplotsset{width=.9\linewidth}

\lstset{
  language=C,
  basicstyle=\ttfamily \small,
  flexiblecolumns=false,
  basewidth={0.5em,0.45em},
  boxpos=t,
}

\definecolor{skRed}{RGB}{155,25,25}
\newcommand{\stefan}[1]{
  {\color{skRed}[{\color{red}{SK}} #1]}}

% ==================================================
\setcounter{section}{0} % Start sections with 1, not 0
\begin{document}

\title{Replication on multicore considering hierarchy and
  characteristics of the network}

% email address
\newcommand{\eaddr}{stefan.kaestle@inf.ethz.ch}
\newcommand{\email}{\href{mailto:\eaddr}{\eaddr}}

\author{Stefan Kaestle\\
  \email \\
  Systems Group, ETH Zurich}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

There are two problems:
\begin{enumerate}
\item Performance of distributed algorithms on multicores. Programmers
  don't get it right due to different complexity measures. We deal
  with this by improving these algorithms. This will lead to higher
  performance of existing algorithms.
\item Diversity of hardware. Hand-tuning algorithms is tedious. Need
  to do this automatically. To evaluate this, we compare the average
  performance of our automatic configuration on a wide range of
  multicores with performance of a single hand-tuned implementation.
\end{enumerate}

\paragraph{What do you want to enable?} Increase algorithm performance
on multicores by applying distributed principles to overcome
scalability challenges on such machines. 

\paragraph{What problem are you solving, and why is it hard?} We are
applying distributed algorithms to multicores to enable better
scalability. However, characteristics of a multicore a different to
those of traditional distributed systems. Traditional algorithms need
to be reevaluated for multicores.

\paragraph{What's the related work?} People apply techniques from
distributed systems to deal with scalability challenges on multicores,
e.g.\ databases~\cite{Salomie2011, Wiesmann2000} and operating
systems~\cite{fos:osr09, tornado:osdi99, barrelfish:sosp09}. But they
don't to it properly. They do not consider machine characteristics or
apply the wrong distributed technologies. Also, what they do is rather
ad hoc. 

\paragraph{What new idea(s) will solve the problems?} Instead of just
reusing distributed algorithms, we reevaluate them for multicores and
investigate the impact of the multicore network model on algorithm
performance.

\paragraph{How will you go about it?} We investigate the problem for
atomic-broadcasts since many problems in distributed systems can be
reduced to this communication primitive. Traditional implementations
are sending requests to all nodes in parallel to hide high propagation
delays. %
However, this does not work on multicores, since the propagation time
is not dominating any longer. %
Instead, we build a tree for communication to parallelize transmit and
receive cost across nodes. This has been done before (BF SOSP, IBM,
.. ), but not for the general case of multicore communication. 

\paragraph{How will you know and show it works?} We will use a
microbenchmark measuring broadcast cost and compare our tree
implementation to the sequential case. Maybe we put some high-level
applications on top of it.

\paragraph{What is your hypothesis?} Performance of distributed
algorithms can be improved if characteristics of multicores are
considered when building and/or selecting them. %
For the broadcast example, this means: the time complexity for a
networks with dominating transmit and receive time will be $O(log(n))$
instead of $O(n)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related work}

A multicore aware broadcast has been implemented in~\cite{Tu2008}. It
takes the cache architecture of the machine into consideration for
building the broadcast. It is however for larger messages (starting at
4K) and it does not seem to be performing very well (numbers are given
in microseconds -6). 4K messages are 52 microseconds, which is 150000
cycles. For synchronization primitives, a cache line is sufficient.

Another tree implementation with MPI in mind was done
in~\cite{Graham2008}. They have comparable numbers to what we found. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The multicore network model}

% selecting hard
Characteristics of the network influence the performance of
distributed algorithms. Due to the heterogeneous combinations of
complex networks on multicores, selection of algorithms is
particularly hard.

% model
We express the network characteristics in a multicore network
model. This model at this stage is by no means complete. We are going to
extend it over time to address more complexities of current and future
multicores.

% graph
We represent the multicore network as a graph. The nodes in this graph
correspond to cores, and edges the communication channels between
nodes. The machines we consider for now only have bi-directional
communication links. Other machines (like the SCC) have
uni-directional links, which is why we model the graph as directed
graph.

% shared memory -> fully meshed
This graph is fully meshed for shared memory machines. Every core can
communicate with every other node via the cache coherence protocol.

\subsection{Node characteristics} 

Every node (i.e.\ core) in the system has characteristics associated
with it:

\begin{description}
\item[synchrony] Parts of a multicore machine are synchronous. Hence,
  one characteristic of a node is an identifier for the synchrony
  cluster of a node.
\item[$t_{send}$] Time required to send a message, i.e.\ marshalling
  and queuing the message
\item[$t_{recv}$] Time required to receive a message, i.e.\
  dequeuing, unmarshalling and demultiplexing a channel.
\item[failure] Can nodes fail? If so, how? (Byzantine, \ldots)
\end{description}

\subsection{Link characteristics} 

The network model is defined by communication channels, which in turn
are defined by a set of attributes (here sorted by priority):

\begin{description}
\item[latency] (quantitative) between each pair of nodes (per-edge)
\item[breakdown] (quantitative) of message send cost: Ethernet has
  dominating propagation time vs.\ dominating send and receive time on
  multicores (per-node)
\item[bounded delivery]
\item[reliability] (loss, link failure, in-order delivery, phantoms,
  corruption, duplicated messages): Ethernet is not reliable,
  multicore interconnect networks often are
\item[Security] \& and failure detection (and the cost for that)
\end{description}

% Assumptions
We assume that the cost of sending a message to the same node is 0,
which is not true, since even using a highly optimized implementation
for local communication (like LMP) has a non-negligible cost.

% Limitations
What we do not consider yet is link congestion. 

\subsection{Acquiring the model}

% Model given
We assume that the model is given (if it is not, we can do online
measurements and read some specs to find the relevant information). We
just define one ourselves for now or build one manually for a
particular machine. In a real-world scenario, this does not work. The
model needs to be created automatically for a particular machine (due
to the diversity of machines, and also the pace at which hardware changes)

\subsection{Example}

An example of a machine model, which approximates a 2x2x1 nos box can
be found in Figure~\ref{fig:full_nos}

\begin{figure}
\begin{tikzpicture}[>=latex,line join=bevel]
  \pgfsetlinewidth{1bp}
\input{graphs/full_nos}
\end{tikzpicture}
\caption{Network model of a 2x2x1 machine}
\label{fig:full_nos}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Example: Atomic broadcast
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Atomic Broadcast}

We build our atomic broadcast based on an overlay network connecting
all nodes of a given multicore machine. 

As a first step, we evaluate tree based overlay networks. Other
potentially interesting topologies are rings.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Tree}

We now look at tree based atomic broadcast implementations. 

The first challenge is to find efficient spanning trees for arbitrary
machines. These machines are represented by a model, which we
described earlier.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Divide and conquer}

We divide the space into clusters. In every round, we further split up
all cluster into smaller clusters and connect them with the minimal
link. 

We find this link by searching for links that have start and
end node in different regions of the most recent split. Out of these
links, we pick the cheapest ones. We ignore links whose start or end
node have a too high degree in the spanning tree already.

Assuming that the choice of node IDs represents the topology to some
extend, splitting them up into distinct clusters avoids contention, as
two separate sub-trees are processed in different areas of the
interconnect network.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Clustering}

Another idea is to employ clustering. One example is to base this on
NUMA domains such that every NUMA domain corresponds to one cluster. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Minimum-Spanning Tree}

We can apply a minimum spanning tree algorithm to the machine model
graph to find a number of links such that these links connect all
nodes at a minimum cost.

We have implemented such an algorithm and found out, that it is not a
good solution in the general case, since it does not consider
parallelism. Naturally, we would like to parallelize send operations
to different nodes, which allows them to send messages in parallel. 

\stefan{We have an example for this, where the MST is essentially a
  path through the graph}

An important variable in constructing such a tree is the degree of
nodes. If the send cost $t_s$ is smaller than the propagation time
$t_p$,  $d = \lceil \frac{t_p}{t_s} \rceil$ messages can be send to
hide propagation of messages. Hence, a tree with degree $d$ should be
ideal to minimize latency, but only for an acknowledged protocol.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Scheduling}

% Tree -> scheduling
Assuming the tree (or some other kind of overlay network), there is a
\emph{scheduling problems} for the order in which to send messages to
children. The intuition is to send on long-delay links first to hide
the more expensive latencies, as this link is dominating total send
cost.

\stefan{We have experiments showing this}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example tree}

We show the multicast tree automatically generated from a fully meshed
machine model of a 8x4x1 sample multicore (gruyere) in
Figure~\ref{fig:mst_gruyere}. We get this tree by applying a minimum
spanning tree algorithm on a multicore model encoding link latencies.

\begin{figure}
\begin{tikzpicture}[>=latex,line join=bevel,scale=.5]
  \pgfsetlinewidth{1bp}
\input{graphs/mst_gruyere}
\end{tikzpicture}
\caption{Multicast tree automatically found for a 8x4x1 multicore}
\label{fig:mst_gruyere}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Broadcast protocol}

% Our implementation
Assuming the tree, we now build an atomic broadcast for multicore
machines. Our implementation is based on the Barrelfish UMP
interconnect driver. It provides reliable channels with in-order
delivery. Communication starts at the root node, which acts as a
sequentializer. See~\ref{algo:ab} for details.

\newcommand{\textc}[1]{{\color{gray} {\footnotesize #1}}}
\begin{algorithm}[H]
\SetCommentSty{textc}
\SetKwInOut{Assumptions}{assumptions}
\Assumptions{Underlying communication channel is reliable and in-order}
\SetKwProg{Fn}{Function}{}{end}%
\SetKwFunction{receive}{on\_receive}%
\SetKwFunction{waitchild}{wait\_for\_children}%
\SetKwFunction{send}{send}%
\SetKwFunction{icsend}{send\_bc\_request}%
\SetKwFunction{icsendack}{send\_bc\_ack}%
\SetKwFunction{handlemessages}{handle\_other\_messages}%
  %
  \KwData{List of processes $p$, broadcast tree as graph $(V, E)$}
  \KwResult{Tree based atomic broadcast using a sequentializer}
  % 
  \BlankLine
  \Fn(\tcp*{Receive a message}){\receive{$client$, $m$}}{
    \For(\tcp*{For all children}){$c \leftarrow \{ c: \exists (self, c) \in E \} $}{
      \icsend{c}
    }
    \waitchild{}\;
    \icsendack{$client$}\;
  }
  % 
  \BlankLine
  \Fn(\tcp*{Send a message}){\send{void}}{
    \tcc{Need to wait for acknowledgment before returning to
      caller. Otherwise, sender might see his own request before some
      other request, that the sequentializer decided to handle first}
    \icsend{$V_{root}$}\tcp*{Relay msg (sequentializer)}
    \While{no answer received}{
      \handlemessages{}\tcp*{Otherwise, deadlocks}
    }
  }
  \caption{Atomic broadcast on reliable communication channels}
  \label{algo:ab}

\end{algorithm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Barrelfish implementation}

When implementing the protocol in Barrelfish, we found several
practical problems, which we will discuss briefly in this section.

We kick-start our protocol connecting every process with all other
processes to get a fully-meshed network of channels.

We use a round-based algorithm to open channels. Then, every node
knows exactly the source of an incoming connection. We formalize this
algorithm in Algorithm~\ref{algo:ab_bind}.

This is required for Barrelfish UMP communication channels since on
bind, no source identifier is send along\footnote{Check if this is
  actually true, and even if it is true, if is a Barrelfish problem,
  and not a general one}.

\begin{algorithm}[H]
  %
  \SetKwInOut{Assumptions}{assumptions}
  \Assumptions{Processes have unique contiguous
    identifiers starting at 0}
  \BlankLine
  %
  \SetKwArray{c}{channels}
  \SetKwFunction{connectNode}{connectNode}
  \SetKwFunction{listen}{listen}
  \SetKwFunction{barrier}{barrier}
  % 
  \KwData{process id $p$, round $r$, %
    each process an array of channels \c}
  \KwResult{Fully-meshed network of processes}
  % 
  \BlankLine
  %
  $r \leftarrow 0$\;
  \For{$i \leftarrow 0$ \KwTo $num(p)$}{
    \eIf{$p=i$}{
      \For{$o \leftarrow i+1$ \KwTo $num(p)$}{
        \c{$o$} $\leftarrow$ \connectNode{$o$}\;
      }
    }{
        \c{$i$} $\leftarrow$ \listen{}\;
    }
    \barrier{} \tcp*{Otherwise, reordering possible}
  }
  \caption{Establish fully-meshed network of channels}
  \label{algo:ab_bind}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Mechanisms}

\subsection{Aggregation}

Similarly to what has been done in wireless sensor networks (where it
also matters to reduce the number of messages, but other reasons:
power consumption), we can do aggregation in nodes. In difference to
traditional distributed systems, this works, because it is easy to
deploy custom software on every node in the network. Classical
distributed systems do not typically allow this. Furthermore, reducing
the number of messages at the price of higher complexity does not make
sense there.

Examples for aggregation: number of nodes agreeing to something, find
capabilities (concatenate core ids). 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Example}

We show an example broadcast tree for a 8x4x1 AMD Barcelona machine
(gruyere) in Figure~\ref{fig:qrm_tree_gruyere}.

\begin{figure}
  \input{qrm_tree_gruyere}
  \caption{Tree of cores for broadcast on gruyere}
  \label{fig:qrm_tree_gruyere}
\end{figure}

\paragraph{Observations} Reducing the number of children also helps in
select. It reduces the number of ``channels'' to poll, and therefore
the latency of detecting messages. Instead of

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental results}

\paragraph{Current numbers} Current numbers are listed in
Table~\ref{tab:bc_measurements}. 

\begin{table}[htb]
  \centering
  \begin{tabular}{lrrrr}
    \toprule
    broadcast algorithm & \multicolumn{2}{c}{nos5} & \multicolumn{2}{c}{gruyere} \\
      & cycles & error & cycles & error \\
    \midrule
    sequential &  4096.1 &  105.2 & 136751.9 &   3061.5 \\
    batch      &  2408.0 &  181.9 &  57360.8 &   5271.5 \\
    \bottomrule
  \end{tabular}
  \caption{Broadcast measurements}
  \label{tab:bc_measurements}
\end{table}

\paragraph{Minimal cost of sending a tree-broadcast} %
Plot~\ref{pgfplot:201303141819} shows the cost of flooding a sub-tree
(with the 50\% worst measurements dropped). The group communication is
based on a binary tree. Core 0 is the root, cores 1 and 2 are its
children etc.

The average cost is really high (probably a scheduling issue). But the
minimal numbers show what is possible. The numbers achieved are easily
explainable. The cost is increasing logarithmic with the number of
nodes reached by the broadcast (as expected). Every level in the tree
adds an additional 3500 cycles to the tree. Node 0 takes significantly
longer. I don't know yet why that is.

\begin{figure}
  \caption{Execution time for a broadcast with ACK on gruyere. The
    cost is for execution for the sub-graph starting at the given
    node. Refer to Figure~\ref{fig:qrm_tree_gruyere} for a
    visualization of the broadcast tree used. }
  \label{pgfplot:201303141819}
  \begin{tikzpicture}
    \begin{axis}[
      xlabel=core id,
      scaled y ticks = false, % prevent 10^x stuff
      y tick label style={/pgf/number format/fixed},
      ylabel={cost for subtree [cycles]}]
    \addplot[
      color=red,
      very thin,
      mark=*,
      mark options={%
        scale=.4
      },
      error bars/y dir=both,
      error bars/y explicit] coordinates {
      (0,9932.3) +- (564.4,564.4)
      (1,8240.1) +- (298.5,298.5)
      (2,8259.6) +- (549.4,549.4)
      (3,6206.3) +- (225.1,225.1)
      (4,5914.9) +- (399.2,399.2)
      (5,6033.5) +- (462.2,462.2)
      (6,6070.4) +- (434.3,434.3)
      (7,4530.4) +- (188.6,188.6)
      (8,3163.4) +- (246.1,246.1)
      (9,3403.0) +- (285.3,285.3)
      (10,3650.7) +- (336.5,336.5)
      (11,3559.0) +- (318.8,318.8)
      (12,3558.1) +- (284.8,284.8)
      (13,3567.5) +- (304.5,304.5)
      (14,3476.3) +- (290.2,290.2)
      (15,2711.7) +- (151.9,151.9)
      (16,614.0) +- (17.5,17.5)
      (17,606.2) +- (17.3,17.3)
      (18,636.2) +- (72.5,72.5)
      (19,641.3) +- (46.3,46.3)
      (20,583.8) +- (46.7,46.7)
      (21,577.8) +- (38.3,38.3)
      (22,561.8) +- (18.1,18.1)
      (23,603.5) +- (56.6,56.6)
      (24,589.0) +- (33.4,33.4)
      (25,582.9) +- (33.2,33.2)
      (26,571.7) +- (16.3,16.3)
      (27,581.6) +- (36.6,36.6)
      (28,564.0) +- (16.4,16.4)
      (29,564.0) +- (20.8,20.8)
      (30,551.6) +- (13.0,13.0)
      (31,596.2) +- (51.4,51.4)
    };
    \end{axis}
  \end{tikzpicture}

\end{figure}
  
\input{gruyere_bc_seq}

\begin{itemize}
\item Move server to a core != 0
\item Use low-level UMP stuff
{
\renewcommand{\labelitemi}{\checkmark}
\item disable yielding
}
\item run several request in parallel, give them IDs, can use in the
  measurement struct. Good for everything having transactions (DB,
  transactional memory, consistency in replication systems)
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future work}

\begin{itemize}
\item Arguing that group communication/atomic broadcast and showing
  that we can do it well might be enough (appeal to atomic broadcasts
  as the foundation for other distributed algorithms, and the MPI
  primitives, that can/need to be mapped to group-communication (have
  a list of them) 
\item Need higher-level applications, such as:
  \begin{itemize}
  \item octopus
    \begin{itemize}
    \item higher level application?
    \end{itemize}
  \item capability system? \stefan{Ask Simon how expensive revocation
      currently is}
  \item a database with replication and consistency maintenance
    \begin{itemize}
    \item SharedDB? (buffers between operators, but no synchronization
      except for access to buffers, which are multiple writers, one
      reader)
    \item Crescando (some kind of state machine replication)
    \end{itemize}
  \end{itemize}
\item Machine model for topology aware tree
  \begin{itemize}
  \item Talked to Pravin about this a bit
  \end{itemize}
\item MPI collectives (as in~\cite{Tu2008})
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\bibliographystyle{plain}
\bibliography{defs,db,mendeley}

\label{LastPage}

\end{document}
