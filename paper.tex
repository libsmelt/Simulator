\documentclass{article}
\usepackage{url,color,xspace,verbatim,subfig,ctable,multirow,listings}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{txfonts}
\usepackage{rotating}
\usepackage{paralist}
\usepackage{subfig}
\usepackage{graphics}
\usepackage{enumitem}
\usepackage{times}
\usepackage{amssymb}
\usepackage[colorlinks=true]{hyperref}
\usepackage[ruled]{algorithm2e}
\usepackage[toc,page]{appendix}
\usepackage{fancyhdr}
% ==================================================

\graphicspath{{figs/}}
\urlstyle{sf}

% tikz stuff
\usepackage{tikz}
\usepackage{pgfplots}

% configuration
\usetikzlibrary{shapes,positioning,calc,snakes,arrows,shapes,fit,backgrounds}
\pgfplotsset{width=.9\linewidth}
\usepgfplotslibrary{external}
\tikzexternalize

\lstset{
  language=C,
  basicstyle=\ttfamily \small,
  flexiblecolumns=false,
  basewidth={0.5em,0.45em},
  boxpos=t,
}

\newcommand{\etal}{{\it et al.}\xspace}
\newcommand{\naive}{na\"{\i}ve\xspace}
\newcommand{\Naive}{Na\"{\i}ve\xspace}
\newcommand{\textc}[1]{{\color{gray} {\footnotesize #1}}}

\fancyhf{}
\fancyfoot[L]{\today}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}
\pagestyle{fancy}

% machines
\newcommand{\ziger}{Ziger (AMD Istanbul 4x6x1)}

\definecolor{skRed}{RGB}{155,25,25}
\newcommand{\stefan}[1]{
  {\color{skRed}[{\color{red}{SK}} #1]}}

\setcounter{section}{0} % Start sections with 1, not 0
\begin{document}

\title{Adaptive broadcast tree for multicores}

% email address
\newcommand{\eaddr}{stefan.kaestle@inf.ethz.ch}
\newcommand{\email}{\href{mailto:\eaddr}{\eaddr}}

\author{Stefan Kaestle\\
  \email \\
  Systems Group, ETH Zurich}

\maketitle

% keywords: modeling, simulation, overlay networks, scheduling

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

Distributed algorithms are increasingly used to overcome scalability
challenges of multicore machines. Examples are
databases~\cite{Salomie2011, Wiesmann2000} and operating
systems~\cite{fos:osr09, tornado:osdi99, barrelfish:sosp09}.

% What do you want to enable?
We want to investigate how to achieve better performance of these distributed
algorithms across a wide range of multicore machines without manually
tuning the implementation to characteristics of individual machines.

% What problem are you solving, and why is it hard?
The problem we are tackling is an increase in complexity and diversity
of modern multicore machines. Multicores come in many flavors
depending on vendor and product line of the machine. They also change
heavily over time. Consequently, characteristics of such machines are
fundamentally different. Examples are the number of cores, NUMA
configurations, interconnect topologies, propagation time on the
interconnect and availability of shared resources such as
caches. These characteristics are hard~\cite{Cavage2013} to
understand, but important to consider for application performance.

% New ideas
Instead of manually tuning algorithms to characteristics of individual
machines, we automatically configure distributed algorithm based on a
machine model. This is populate with online measurements to express
detailed information about machine characteristics. We then use
this model to predict algorithm performance for the specific machine
and select a good implementation automatically and dynamically at
run-time.

% How will you go about it?
As an example, we investigate atomic broadcasts for multicore
machines. The space of possible implementations is large reaching from
shared memory implementations to message based topologies for
different topologies of overlay networks. Such topologies are: minimum
spanning trees, binary trees, rings as well as clustering-based
approaches. Assuming the overlay network, we then need to decide for
every node the order in which to send messages. This is a
\emph{scheduling} problem.

% How do we show it works
We auto-configure a wide range of different multicore machines and
compare the performance of our implementation with hand-tuned
implementations on all of these machines.
% Hypothesis
Our hypothesis is that automatic tuning of distributed algorithms 
to machine characteristics is worth
doing. Obviously, we cannot achieve performance of hand-tuned
implementations, but we hope to get close enough to argue that loosing
a bit of performance to avoid tedious manual reconfiguration is worth
if for many applications (while others, where performance
\emph{really} matters, might still want to manually configure their
stuff).

% three-step approach
We break the problem down into three steps:
\begin{inparaenum}[\itshape 1\upshape)]
\item We first represent multicore machines by a model. We describe
  this model in Section~\ref{sec:model},
\item We then find an overlay for a concrete network model. This
  overlay network describes a topology (such as a tree or a ring) for
  communication within the machine. Algorithms to select overlay
  networks are described in Section~\ref{sec:overlay}, and
\item Given the overlay, we need to decide for every node in which
  order to send messages. We investigate this scheduling problem in
  Section~\ref{sec:scheduling}.
\end{inparaenum}

\begin{figure}[htb]
  \centering
  \includegraphics[width=\linewidth]{Overview_Model_Evaluation_Parser}
  \caption{Overview of configuration of atomic broadcast using a Model 
    \stefan{Draw figure properly}}
  \label{fig:overview}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Distributed algorithms}
\label{sec:distalgo}

In order to evaluate our ideas, we pick two concrete distributed
algorithms and implement them for a multicore machine:

\paragraph{Atomic broadcast} An Atomic broadcasts is a broadcast
messaging protocol that is reliable in the sense that if a message is
received by one of the participating nodes, it is also received by all
other nodes. Furthermore, the order of messages as seen by all
participants is the same. Messages are immutable, i.e.\ all receivers
read exactly the same message.

Atomic broadcasts are frequently used to implement higher-level
distributed algorithms on top of it: examples are replication such as
state machine replication. As a first step, we evaluate the
performance of sending one message as a broadcast to all
nodes. Broadcasts are one of the most important communication
operations for parallel applications~\cite{Bruck1992}.%
\stefan{Also: Database joins}.

\paragraph{Barriers} \stefan{Explain}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The multicore network model}
\label{sec:model}

% selecting hard
Characteristics of the network influence the performance of
distributed algorithms. 
% model
We express these network characteristics in a multicore network
model. This model at this stage is by no means complete. We are going to
extend it over time to address more complexities of current and future
multicores.
% static
Our network model is \emph{static}, which in particular implies that
we do not consider run-time effect such as congestion for the moment.

% graph
We represent the multicore network as a \emph{directed graph}. The nodes in
this graph correspond to cores, and edges to communication channels
between nodes. The machines we consider for now only have
bi-directional communication links. Other machines (like the SCC) have
uni-directional links, which is why we model the graph as directed
graph.
% shared memory -> fully meshed
This graph is \emph{fully meshed} for shared memory machines. Every core can
communicate with every other node via the cache coherence protocol.

% machines hierarchical
Multicore machines are hierarchical. Processor cores are grouped in
NUMA nodes with shared caches. These NUMA nodes are then connected to
each other by increasingly complex interconnect networks. 
% NUMA affinity -> model
We encode NUMA node affinity in our model. This allows to break down
programming of a multicore machine into two distinct instances. We
solve one instance of the problem between NUMA nodes, and then, in a
second step, within each NUMA node. These two steps can be executed
independently and different algorithms can be used in both case.

% why it makes sense?
If cores on the same NUMA node share a cache, it makes sense to
leverage this hardware feature to implement shared-memory algorithms
on top of it. %
Communication across NUMA nodes is realized sending messages across
the packet-based interconnect network. Using message-passing based
implementations is the natural choice. %
Shared memory algorithms and message-passing based algorithms can be
composed together to program hierarchical machines similarly to what
was previously shown for composing of shared-memory
algorithms~\cite{Alistarh2012}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Node characteristics} 
\label{sec:model_nodes}

\stefan{Not sure yet if we really need this, but it should be helpful
  for treating the machine hierarchically}

Every node (i.e.\ core) in the system has characteristics associated
with it.

\begin{description}
\item[NUMA affinity] A list of cores on the same NUMA node.
\item[Synchrony] Synchronous systems are characterized by two
  attributes: First, cores execute their programs in lock-steps and
  second that message delivery time is bound.
  % 
  The existence of lock-steps implies the existence of a global time.
  This is often true on multicore machines since cores are driven by
  the same quartz or, if not, they are synchronized such that the
  jitter is less than a cycle, which leads to cores seeing the same
  time. %
  Bounded delivery time is harder to reason about. CPUs on multicores
  are typically time-multiplexed. On such systems, several programs
  execute on the same processing unit one at a time. A scheduler
  decides the order in which to run these applications. In very
  contented systems, timely receipt of messages cannot be guaranteed
  globally for all applications since many of them compete for a CPU
  core. Even if we could guarantee timely delivery of messages by use
  of a deterministic scheduler, worst-case propagation times would
  still be orders of magnitude higher than best-case propagation
  (which is essentially zero). \stefan{gang-scheduling?}
\item[Failure] Can nodes fail? If so, how? (Byzantine, crash). We do
  not consider failures at the moment, but believe that we will
  inevitably have to do so for future multicores, where it is unlikely
  that hardware can hide failures from software.
\end{description}

%-------------------------------------------------
\subsection{NUMA characteristics}
\label{sec:model_numa_nodes}

\stefan{Maybe characteristics of NUMA nodes do not have to be encoded
  separately, but as part of the node characteristics?}

Some characteristics of multicore communication stem from the NUMA
hierarchy. Thus, such characteristics can be encoded separately in the
model.

\begin{description}
\item[hop count] Number of hops to every other NUMA node. The cost of
  sending a message in a multicore machines does not so much depend on
  the distance on the interconnect networks as on the number of hops
  on such a path. Propagation on the wire is essentially for free due
  to short distances between cores. %
  On a multi-hop path, however, packages traversing the interconnect
  need to be buffered. This is expensive. Depending on the machine,
  some routing is executed on every intermediate route, which
  increases the latency further.
\item[hop count histogram] For every NUMA node, we want to know how
  many other NUMA nodes can be reached with $n$ hops. This tells us
  something about how well such nodes are connected to other NUMA
  nodes. The intuition is that it makes sense to send a message to a
  well connected NUMA node early in time, to ``spread'' out a message
  as quickly as possible.
\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Link characteristics} 
\label{sec:model_links}

The network model is defined by communication channels, which in turn
are defined by a set of attributes (here sorted by priority):

\begin{description}
\item[cost breakdown] (quantitative) of message send cost:
  dominating propagation time vs.\ dominating send and receive time on
  multicores (per-node). Our model is currently limited to only the
  breakdown of the cost for sending messages. Maybe we do not strictly
  need to know about propagation time, as it is negligible independent
  of were messages are sent. Relevant seems to be the number of hops
  rather than the latency expressed in a concrete time.
  \begin{description}
  \item[send time] We assume this independent of which node we
    communicate with (which is true for most of our machines when
    using sender-side buffering)
  \item[receive] On shared memory machines, receiving messages is
    realized by reading a memory location. When the sender writes the
    message, the receiver's copy of the cache-line is invalid. The
    next read on it causes a transfer of the cache line from the
    sender's to the receiver's cache, which seems to have a cost that
    is growing with the number of hops on the interconnect for our
    machines (although, on some machines, this is only roughly true:
    communication with different NUMA nodes at the same interconnect
    hop distance varies a bit. We ignore this fact for now.)
  \end{description}
\item[bounded delivery]
\item[reliability] (loss, link failure, in-order delivery, phantoms,
  corruption, duplicated messages): 
  multicore interconnect networks often are
\end{description}

% Assumptions
We assume that the cost of sending a message to the same node is 0,
which is not true, since even using a highly optimized implementation
for local communication (like LMP) has a non-negligible cost.

% Limitations
What we do not consider yet is link congestion. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Acquiring the model}

% Model given
We assume that the model is given. We just define one ourselves for
now or build one manually for a particular machine. In a real-world
scenario, this does not work. The model needs to be created
automatically for a particular machine (due to the diversity of
machines, and also the pace at which hardware changes)

We now make up a machine model for evaluation. This model is based on
a 8x4x1 AMD Barcelona machine. The topology of such a machine is shown
in Figure~\ref{fig:gruyere}.

Each of the eight NUMA nodes consists of four cores. We approximate the
cost of sending messages within nodes as $1$ and across nodes as
$10*num(hops)$.

Send and receive time are $10$ each, i.e.\ in the order of propagation
over a cross-NUMA link.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}[
    xscale=.7,
    yscale=.5,
    every node/.style={draw,fill=red!10,minimum width=2cm,minimum height=1cm}
    ]
    \node (c1) at ( 0, 4) {node 0};
    \node (c2) at ( 4, 4) {node 1};
    \node (c3) at ( 8, 4) {node 2};
    \node (c4) at (12, 4) {node 3};

    \node (c5) at ( 0, 0) {node 4};
    \node (c6) at ( 4, 0) {node 5};
    \node (c7) at ( 8, 0) {node 6};
    \node (c8) at (12, 0) {node 7};

    % top horizontal
    \draw[thick] (c1) -- (c2);
    \draw[thick] (c2) -- (c3);
    \draw[thick] (c3) -- (c4);
    % bottom horizontal
    \draw[thick] (c5) -- (c6);
    \draw[thick] (c6) -- (c7);
    \draw[thick] (c7) -- (c8);
    % vertical
    \draw[thick] (c1) -- (c5);
    \draw[thick] (c2) -- (c6);
    \draw[thick] (c3) -- (c7);
    \draw[thick] (c4) -- (c8);
    % cross
    \draw[thick] (c3) -- (c8);
    \draw[thick] (c4) -- (c7);
  \end{tikzpicture}
  \caption{Interconnect topology of 8x4x1 AMD Barcelona machine}
  \label{fig:gruyere}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Overlay selection}
\label{sec:overlay}

For a specific model, we now need to find ``the right'' implementation
of algorithms to program it. We build our atomic broadcast based on a
subset of links offered by the model such that all nodes of a given
multicore machine can be reached. Atomic broadcast guarantees that 1)
if one node receives a message, all other nodes receive it as well,
and 2) that all nodes see the message in the same order.

First, we discuss what kind of topologies we use to communicate
between nodes. We evaluate tree based implementations: binary trees,
minimum spanning trees, hierarchical tress and clustering
techniques. Other potentially interesting topologies are rings.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Tree Topology}

We now look at tree-based atomic broadcast implementations. The first
challenge is to find efficient spanning trees for arbitrary
machines. We now discuss different strategies to select trees based on
the model representing the machine.

Several optimizations are possible. First, nodes further up the tree
should have a higher degree i.e.\ send more messages so that they do
not idle~\cite{Bar-Noy1994}. An example of such a tree is a Fibonacci
tree, which is known to be optimal for the case that send and receive
time are equal~\cite{Bar-Noy1994}. 

In contrast, we assume that the model is given, which allows us to
simulate sending messages along the broadcast tree. Whenever a node is
idle in the model, it will send a message to one of the cores, that
did not receive any messages yet. For the special case that send
equals receive time, this should also yield a Fibonacci tree.

%-------------------------------------------------
\subsubsection{Binary Tree}

A very \naive strategy to build a tree from machine models is the use
of a binary tree with root in core 0. Every node $n$ has two children
$2(n+1)-1$ and $2(n+1)$.

The benefit of such a tree is that the time complexity is guaranteed
to be $O(\log{n})$. The downside is that it is not considering the
machine topology. Unnecessary communication across NUMA nodes might be
introduced. 

We show an example for such a tree for a 8x4x1 AMD Barcelona machine
(gruyere) in Figure~\ref{fig:qrm_tree_gruyere}.

\begin{figure}
  \input{qrm_tree_gruyere}
  \caption{\Naive binary tree of cores for broadcast on gruyere}
  \label{fig:qrm_tree_gruyere}
\end{figure}

%-------------------------------------------------
\subsubsection{Minimum-Spanning Tree}
\label{sec:mst_tree}

We can apply a minimum spanning tree algorithm to the machine model
graph to find a number of links such that these links connect all
nodes at a minimum cost.

We have implemented such an algorithm and found out, that it is not a
good solution in the general case, since it does not consider
parallelism. Naturally, we would like to parallelize send operations
to different nodes, which allows them to send messages in parallel. 

An example is obvious in Figure~\ref{fig:mst_gruyere_operations}. The
level of parallelism is only two. Cores 00 to 15 are dealt with in
parallel to cores 16 to 31. Other than that, there is no further
parallelism although it is possible to ``split up'' communication with
every new ``round'' (i.e.\ send operations of nodes).

An important variable in constructing such a tree is the degree of
nodes. If the send cost $t_s$ is smaller than the propagation time
$t_p$, $d = \lfloor \frac{t_p}{t_s} \rfloor$ messages can be send to
hide propagation of messages. Hence, a tree with degree $d$ should be
ideal to minimize latency. For multicore interconnect networks,
however, we expect $d<1$. Thus, we do not look into this in detail
right now.

Reducing the degree of nodes also helps for the select operation. It
reduces the number of memory locations to poll, and therefore the
latency of detecting messages.

We show the multicast tree automatically generated from a fully meshed
machine model by applying a minimum spanning tree algorithm in
Figure~\ref{fig:mst_gruyere}.

\begin{figure}
\begin{tikzpicture}[>=latex,line join=bevel,scale=.5]
  \pgfsetlinewidth{1bp}
\input{graphs/mst_gruyere}
\end{tikzpicture}
\caption{Multicast tree automatically found for a 8x4x1 multicore}
\label{fig:mst_gruyere}
\end{figure}

%-------------------------------------------------
\subsubsection{Hierarchical}

We now consider NUMA node for coming up with a broadcast tree. We
select one coordinator node in every node and build a binary tree
for the coordinators. We call this topology connecting nodes across
NUMA domains the \emph{outer} network.

Each coordinator is also responsible for sending a message to all
other cores of the node. We currently do this sequentially, since the
number of cores in a node is typically very small. Alternatively, a
binary tree could be used as well. We call overlay networks within
NUMA nodes \emph{inner} networks.

We show an example hierarchical tree in
Figure~\ref{fig:gruyere_hierarchy}.

\begin{figure}
\begin{tikzpicture}[>=latex,line join=bevel,scale=.5]
  \pgfsetlinewidth{.5bp}
\input{graphs/final_gruyere_hierarchical}
\end{tikzpicture}
\caption{Hierarchical tree for a 8x4x1 multicore. Nodes 0, 4, 8, 12,
  16, 20, 24 and 28 are coordinators. They are arranged in a binary
  tree starting at node 0. Communication within NUMA nodes is
  sequential (as an example: coordinator node 24 sends a message to
  all cores on the same NUMA node, namely 25, 26 and 27)}
\label{fig:gruyere_hierarchy}
\end{figure}


%-------------------------------------------------
\subsubsection{Clustering}

We discussed earlier in Section~\ref{sec:model} that
multicore machines are hierarchical. We discuss here a more
methodical approach for communication withing hybrid networks.

The idea is to find clusters of cores for whom shared memory
algorithms are more efficient then their message passing-based
counter-parts.

In a shared memory implementation, the cost of enqueueing a message to
a shared memory queue is $t_{write}$. The reads ideally (i.e.\ not
considering contention) happen in parallel, which means $t_{read}$
independent of how many clients read the data, but cause $n$-fault
traffic on the interconnect.

We now assume that the receiving cores shared a cache. Each message is
then available locally for further read operations by other cores
after the first core was issuing a read. This first read forces the
cache-coherency protocol to update (or pull) the message that was
invalidated by the sender write operation.

A shared memory implementation is more efficient for a group of cores
$c_1 \ldots c_n \in C$ if $t_{write} + t_{rem-read} +
(n-1)*t_{local-read}$ is smaller then the cost of sending a message
along the most efficient message-passing topology for this set of
cores.

\begin{algorithm}[htb]
  %%%%% 
  \SetCommentSty{textc}
  \SetKwFunction{sort}{sort} %
  \SetKwFunction{cost}{cost} %
  \SetKwFunction{pop}{pop} %
  \SetKwFunction{shortestmp}{shortest\_mp} %
  \SetKwFunction{costshm}{cost\_shm} %
  \SetKwFunction{cluster}{get\_cluster} %
  \SetKwFunction{icsend}{send} %
  %%%%
  \KwData{Edges E from model}
  %%%%%
  
  \While{True}{
    links $\leftarrow$ \sort{E}\;
    \Repeat{stderr small enough}{
      (start, end) = \pop{links}\;
      clusters += start, end\;
    }
    clusters $\leftarrow $ \cluster{}\;
    \eIf{\cost{\shortestmp{cores}} $<$ \costshm{cores}}{
      cores $\leftarrow$ cluster\;
    }{
      break \;
    }
  }
  \If{cores}{
    Compose algorithm
  }
  %%%%%
  \caption{Algorithm to find shared memory clusters}
  \label{algo:clustering}
\end{algorithm}

%--------------------------------------------------
\subsubsection{Adaptive Tree}

\stefan{Describe how this works and how we pick links}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Ring topology}

Next, we evaluate ring topologies. Rings experience a certain level of
redundancy. The sending node receives the node back on the ring. This
is unnecessary for applications with uni-directional traffic executed
on reliable communication channels

For applications that require some form of feedback (as well as
unreliable channels, which we do not consider at this point), rings
have the advantage that they can piggy-back some information that will
eventually arrive back on the sender. This is beneficial for some
algorithms such as quorums, where nodes report the result of the
quorum back to the sender.

The downside is that some state is required on every node to remember
whether or not a message was received before. If messages are just
forwarded as they arrive, message transport does never terminate.

To add more parallelism, we add a second ring, which we send the
message on in parallel. Acknowledgments, however, only work if
forwarding along the ring is only done after all local nodes (as in
nodes from the outer rings) acknowledge a message. In
Figure~\ref{fig:gruyere_ring}, we visualize an example of two
intertwined ring topologies. Node that the link from node 20 to 8 is a
two hop link and, thus, has a cost of 20 instead of the usual 10.

\begin{figure}
\begin{tikzpicture}[>=latex,line join=bevel,scale=.5]
  \pgfsetlinewidth{.5bp}
\input{graphs/final_ring}
\end{tikzpicture}
\caption{Outer overlay as ring with sequential inner overlay for a
  8x4x1 multicore}
\label{fig:gruyere_ring}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Scheduling}
\label{sec:scheduling}

% Tree -> scheduling
Assuming the tree (or some other kind of overlay network), there is a
\emph{scheduling problems} for the order in which to send messages to
children. The intuition is to send on long-delay links first to hide
the more expensive latencies, as this link is dominating total send
cost.

In Figure~\ref{fig:mst_gruyere_operations}, we visualize sending of a
broadcast message in \naive order. We use the MST given in
Figure~\ref{fig:mst_gruyere}.  When core 08 sends its six messages, it
does so in random order (here: in increasing node ID order). This is
inefficient, as the latency of the broadcast is dominated by cores 12,
24 and 28 rather than cores 9, 10 and 11.

In Figure~\ref{fig:mst_gruyere_operations_sorted} we schedule sending
of messages based on link cost. We sort the outgoing edges by their
weights and send on the most expensive links first. See
Algorithm~\ref{algo:scheduling_link_weight}

\begin{algorithm}[htb]
\SetCommentSty{textc}
\SetKwFunction{weight}{edge\_weight}%
\SetKwFunction{sort}{sort\_by\_edge\_weight}%
\SetKwFunction{icsend}{send}%
  %
  \KwData{Node $n$ sending messages, \\ %
    broadcast tree as graph $(V, E)$, \\ %
    weight function \weight{$E$}
    %
  }
  % 
  \BlankLine
  $nb \leftarrow \{ c: \exists (self, c) \in E \}$\tcp*{Get children}
  $nb \leftarrow $ \sort{$nb$, \weight{}}\tcp*{Sort by edge weight}
  \For(\tcp*{For all children}){$c \leftarrow nb$}{
    \icsend{$c$}
  }
  % 
  \caption{Scheduling in order of outgoing link weight}
  \label{algo:scheduling_link_weight}
\end{algorithm}

A better schedule for sending messages to the children of core 8 would
be to start with the child from which the longest path emerges.

\stefan{TODO: write down algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation}
\label{sec:implementation}

% Our implementation
Assuming the tree, we now implement an atomic broadcast for multicore
machines. Our implementation is based on the Barrelfish UMP
interconnect driver. It provides reliable channels with in-order
delivery and sender-side buffering \stefan{Verify this}. Flow control
is build in for reliability. Communication starts at the root node,
which acts as a sequentializer. See~\ref{algo:ab} for details.

\begin{algorithm}[htb]
\SetCommentSty{textc}
\SetKwInOut{Assumptions}{assumptions}
\Assumptions{Underlying communication channel is reliable and in-order}
\SetKwProg{Fn}{Function}{}{end}%
\SetKwFunction{receive}{on\_receive}%
\SetKwFunction{waitchild}{wait\_for\_children}%
\SetKwFunction{send}{send}%
\SetKwFunction{icsend}{send\_bc\_request}%
\SetKwFunction{icsendack}{send\_bc\_ack}%
\SetKwFunction{handlemessages}{handle\_other\_messages}%
  %
  \KwData{List of processes $p$, broadcast tree as graph $(V, E)$}
  \KwResult{Tree based atomic broadcast using a sequentializer}
  % 
  \BlankLine
  \Fn(\tcp*{Receive a message}){\receive{$client$, $m$}}{
    \For(\tcp*{For all children}){$c \leftarrow \{ c: \exists (self, c) \in E \} $}{
      \icsend{c}
    }
    \waitchild{}\;
    \icsendack{$client$}\;
  }
  % 
  \BlankLine
  \Fn(\tcp*{Send a message}){\send{void}}{
    \tcc{Need to wait for acknowledgment before returning to
      caller. Otherwise, sender might see his own request before some
      other request, that the sequentializer decided to handle first}
    \icsend{$V_{root}$}\tcp*{Relay msg (sequentializer)}
    \While{no answer received}{
      \handlemessages{}\tcp*{Otherwise, deadlocks}
    }
  }
  \caption{Atomic broadcast on reliable communication channels}
  \label{algo:ab}

\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Issues with the Barrelfish implementation}

When implementing the protocol in Barrelfish, we found several
practical problems, which we will discuss briefly in this section.
We kick-start our protocol connecting every process with all other
processes to get a fully-meshed network of channels.
We use a round-based algorithm to open channels. Then, every node
knows exactly the source of an incoming connection. We formalize this
algorithm in Algorithm~\ref{algo:ab_bind}.
This is required for Barrelfish UMP communication channels since on
bind, no source identifier is send along\footnote{Check if this is
  actually true, and even if it is true, if is a Barrelfish problem,
  and not a general one}.

\begin{algorithm}[htb]
  %
  \SetKwInOut{Assumptions}{assumptions}
  \Assumptions{Processes have unique contiguous
    identifiers starting at 0}
  \BlankLine
  %
  \SetKwArray{c}{channels}
  \SetKwFunction{connectNode}{connectNode}
  \SetKwFunction{listen}{listen}
  \SetKwFunction{barrier}{barrier}
  % 
  \KwData{process id $p$, round $r$, %
    each process an array of channels \c}
  \KwResult{Fully-meshed network of processes}
  % 
  \BlankLine
  %
  $r \leftarrow 0$\;
  \For{$i \leftarrow 0$ \KwTo $num(p)$}{
    \eIf{$p=i$}{
      \For{$o \leftarrow i+1$ \KwTo $num(p)$}{
        \c{$o$} $\leftarrow$ \connectNode{$o$}\;
      }
    }{
        \c{$i$} $\leftarrow$ \listen{}\;
    }
    \barrier{} \tcp*{Otherwise, reordering possible}
  }
  \caption{Establish fully-meshed network of channels}
  \label{algo:ab_bind}
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Evaluation}

\stefan{Compare to pure shared-memory implementations, otherwise
  reviewers might argue that there is no need for distributed
  algorithms.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Atomic broadcast}

%--------------------------------------------------
\subsubsection{Comparison to shared-memory implementations}

A shared memory equivalent implementation for atomic broadcasts could
be:
\begin{itemize}
\item Messages should (but don't have to be) cache-line size. This
  prevents false-sharing. Larger messages can be fragmented. 
\item A FIFO queue that guarantees the order of messages (and therefore
  a lock)
\item A counter that is incremented whenever a process reads the
  message from the FIFO queue. To guarantee atomic broadcast
  attributes, elements from the queue must not be removed before all
  processes have read it.
\end{itemize}

This sounds pretty expensive. Need to evaluate this. The question is
whether any sane person would use such a queue for high level
applications. If so, which ones?

There are some libraries providing synchronization primitives such as
barriers, critical sections, atomic updates and locks.

\begin{itemize}
\item Is there an OpenMP equivalent? \emph{OpenMP} has a shared-memory
  based programming model that is targeted to the HPC
  world. \stefan{So what exactly is the relationship between OpenMP
    and MPI? MPI seems to be more low-level. Does OpenMP implement
    MPI?}
\item \emph{Pthreads} also has a shared-memory model for low-end
  systems~\cite{OpenMP_paper}
\end{itemize}

%-------------------------------------------------
\subsubsection{Simulation}

This section shows results for a simulation based on the model
introduced in Section~\ref{sec:mst_tree}. The time given is a
fictional time unit at this point.

\begin{table}[htb]
  \centering
  \begin{tabular}{lllll}
    \toprule
    topology & scheduling & time & factor & figure \\
    \midrule
    MST & naive                     & 241 & 1.00 & 
        \ref{fig:mst_gruyere_operations} \\
    MST & highest link weight first & 151 & 0.63 & 
        \ref{fig:mst_gruyere_operations_sorted} \\
    MST & longest path first        & 151 & 0.63 & 
        \stefan{? AFAIK, same as
        \ref{fig:mst_gruyere_operations_sorted} } \\
    hierarchical & highest link weight first & 151 & 0.63 & \\
    ring & highest link weight first & 181 & 0.75 & \\
    \bottomrule
  \end{tabular}
  \caption{Simulation results for simplified machine model}
  \label{tab:sim_results}
\end{table}

Scheduling based on the longest path does not make a difference for
the current MST, but will be better in many cases. \stefan{We need to
  find a model where this is actually true. But we also need to
  evaluate if the increase in complexity is worth it}

%-------------------------------------------------
\subsubsection{Real hardware}

\stefan{Describe benchmark application} 
\begin{itemize}
\item One process on every core
\item Management process on core 2 (i.e.\ not core 0)
\item Uses atomic broadcast as described in Section~\ref{sec:implementation}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related work}

A multicore aware broadcast has been implemented in~\cite{Tu2008}. It
takes the cache architecture of the machine (and only one particular?)
into consideration for building the broadcast. It is however for
larger messages (starting at 4K) and it does not seem to be performing
very well (numbers are given in microseconds -6). 4K messages are 52
microseconds, which is 150000 cycles. For synchronization primitives,
a cache line is sufficient.

Another tree implementation with MPI in mind was done
in~\cite{Graham2008}. They have comparable numbers to what we found,
but they cannot automatically tune to different machine
characteristics. Our hypothesis is that we can do achieve higher
average performance across a wide range of different multicore
machines without manually adapting the implementation.

Alistarh\etal~\cite{Alistarh2012} show composition of shared-memory
algorithms that perform efficiently under different conditions at
negligible overhead. A similar approach can potentially be applied to
deal with diversity of multicore machines. However, we would have
to extend it to support both shared-memory and message-passing
implementations. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future work}

\newcommand{\nary}{$n$-ary\xspace}

\begin{itemize}
\item Keywords: decomposition~\cite{Cavage2013}
\item Other topologies (mainly based on~\cite{Bruck1992}):
  \begin{itemize}
  \item Fibonacci trees: more efficient since nodes further up the
    tree send more messages, but not considering the hierarchy of the
    machine 
  \item \nary trees: play with the out-degree of nodes. The ideal
    value for the out-degree depends on the machine. For
    $t_{propagation} << max(t_{send}, t_{receive})$, $n = 2$ should be
    optimal, since it still increases parallelism, but the latency
    induced by the $n$ send operation is not too high.
  \end{itemize}
\item Think about synchronous implementations and see if they are
  applicable for some of our machines.
\item Arguing that group communication/atomic broadcast is important
  and showing that we can do it well might be enough (appeal to atomic
  broadcasts as the foundation for other distributed algorithms, and
  the MPI primitives, that can/need to be mapped to
  group-communication (have a list of them)
  \begin{itemize}
  \item MPI\_Bcast: send a broadcast message to every node (including
    the sending one)
  \item MPI\_Scatter
  \item MPI\_Gather
  \item MPI\_Reduce
  \end{itemize}
  These primitives are synchronous. They return only once every other
  node received the message. 
\item Need higher-level applications, such as:
  \begin{itemize}
  \item capability system? \stefan{Ask Simon how expensive revocation
      currently is}
  \item a database with replication and consistency maintenance
    \begin{itemize}
    \item SharedDB? (buffers between operators, but no synchronization
      except for access to buffers, which are multiple writers, one
      reader)
    \item Crescando (some kind of state machine replication)
    \end{itemize}
  \end{itemize}
\item MPI collectives (as in~\cite{Tu2008})
\item \emph{Load balancing in a tree} We could build several rings,
  that do not always include all coordinators and work with read- and
  write-sets. We can select these rings such that they nicely
  integrate with the physical topology. They can also have different
  sizes (e.g.\ a smaller one for read operations and larger ones for
  writes).
\item \emph{Aggregation for convergecast} %
  Convergecast is a way of collecting information from nodes (i.e.\ it
  is kind of the reverse of a broadcast). On the return path,
  information can be aggregated. One example is batching, where several
  pieces of information are grouped in the same message to reduce packet
  processing overhead. Another example is aggregation, i.e.\
  pre-processing of data. One example is pre-calculating the average
  value of child messages if the sink node is not interested in
  individual values. %
  Similarly to what has been done in wireless sensor networks (where it
  also matters to reduce the number of messages, but for other reasons:
  power consumption), we can do aggregation in nodes. In difference to
  traditional distributed systems, this works, because it is easy to
  deploy custom software on every node in the network. Classical
  distributed systems do not typically allow this. Furthermore, reducing
  the number of messages at the price of higher complexity does not make
  sense in classical systems. %
  Examples for aggregation: number of nodes agreeing to something, find
  capabilities (concatenate core ids). 
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Octopus}

Octopus is a coordination service implementation for the Barrelfish
Multikernel operating system based on a key-value store
data-backend. It is, however, centralized. The idea is to make Octopus
a decentralized application.

For that, we extend Octopus such that it can be replicated within a
multicore machine. This will retain scalability for future manycore
machines and potentially outperform a centralized version of Octopus
especially in contented systems.

%--------------------------------------------------
\subsubsection{Key-value store}

One foundation block of Octopus is a key-value store. Since there is
only one copy, the data in there is always consistent. If replicated,
some sort of consistency guarantee would have to be implemented. One
example is \emph{linearizability}, i.e.\ ``accesses occur one at a time
in, some sequential order that is consistent with the order of
invocations and responses''~\cite{lynch}.

One concrete idea is to have one copy of the Octopus data-store
replicated on every NUMA node. One core on every node acts as
\emph{coordinator}, we call the other nodes \emph{slaves}.
Coordinators communicate on a ring. Communication on a local NUMA node
can be realized using read-only shared memory for read access. Write
access needs to be globally ordered and hence communication with other
replicas is required. 

Slaves direct their updates to the local coordinator. Coordinators
send the update request $r$ along the ring and wait for them to be
send back. While passing on requests, coordinators can set a flag to
indicate conflicts. A conflict is another colliding request $r_o$ that
is already in flight. I think we will have to send activity vectors
along with this information! Otherwise, the coordinators requesting
$r$ and $r_o$ will both prevent the other thing from happening and
none of them will be applied! Maybe we need a two-phase commit.

The idea of having a ring is somewhat related to SharedDB. It
optimizes for throughput, not latency!

%-------------------------------------------------
\subsubsection{Synchronization}

It is doubtful that a key-value store as a backend for synchronization
primitives as we want to show efficiency rather than ease of use and
flexibility. We probably rather want to implement new synchronization
algorithms from scratch. See Section~\ref{barriers} for ideas.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Barriers}
\label{barriers}

The idea is to explore barrier implementations. The idea is to
leverage information about the NUMA topology for better performance of
barrier intensive workloads. Every NUMA node has a coordinator node,
that knows how many threads on that node want to enter the
barrier. There is only local communication (possibly using a
share-memory implementation to exploit the shared cache) until the
point where all NUMA local threads did enter the barrier.  Then there
is ``global'' communication with other coordinators on other nodes
using a message-passing based algorithm. We believe that this scales
better than pure shared-memory implementations due to less
interconnect contention.

We will have to compare the performance of such an implementation with
a purely shared-memory based implementation like pthreads and
something entirely message-passing based like MPI versions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\bibliographystyle{plain}
\bibliography{defs,db,mendeley}

\label{LastPage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}

\input{measurements/gruyere_topologies}

Table~\ref{tab:gottardo} shows results for various atomic broadcasts
trees on real hardware as well as our simulator.

The simulator is not very accurate in this case due to the send time
measured being essentially zero on Intel machines. This measurement
does not consider the constant overhead in software for sending a
message that was not part of the original send benchmark.

We either need to send and receive benchmarks with the exact same
framework or measure the constant overhead and add it to the send
cost.

Sequentially sending messages is still expensive even though the send
itself is cheap on Intel machines. This is somewhat unexpected, as the
sender has very low overhead in sending all messages
itself. Sequentially sending all messages however induces several
expensive message transfers across NUMA nodes.

\input{measurements/gottardo_topologies}

\input{measurements/sbrinz_topologies}
\input{measurements/tomme_topologies}
\input{measurements/ziger_topologies}

\end{document}
